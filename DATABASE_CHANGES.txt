================================================================================
TAMU LAW PORTAL - DATABASE INTEGRATION CHANGES
================================================================================
Date: October 9, 2025
Summary: Complete full-stack integration with PostgreSQL, PDF extraction, 
         and one-to-one email logic
================================================================================

NEW FILES CREATED
================================================================================

1. Backend Server: /server/src/index.js
   - Express.js API with 3 endpoints
   - POST /api/applications (submit with file upload)
   - GET /api/applications (get all)
   - GET /api/applications/:id (get single)
   - PDF text extraction using pdf-parse v2
   - One-to-one email logic (auto-replaces old applications)
   - PostgreSQL connection pool with transactions

2. Database Schema: /db/init/001_schema.sql
   - applicants table (applicant_id, name, email UNIQUE, phone, note, created_at)
   - resumes table (resume_id, applicant_id FK, resume_file, cover_letter_file, extracted_text, uploaded_at)
   - CASCADE delete relationship (deleting applicant removes resume)

3. Environment Files:
   - /server/.env (DATABASE_URL, PORT=4000)
   - /frontend/.env (VITE_API_URL=http://localhost:4000)

4. Documentation:
   - DATABASE-SETUP.md
   - PDF-EXTRACTION.md
   - server/README.md

================================================================================
MODIFIED FILES
================================================================================

1. docker-compose.yml
   CHANGE: Port from 5432:5432 → 55432:5432
   REASON: Avoid conflict with local PostgreSQL

2. frontend/src/pages/AdjunctApplicationPage.jsx
   CHANGES:
   - Replaced JSON with FormData for file uploads
   - Added file input refs (resumeInputRef, coverInputRef)
   - Updated API call to send multipart/form-data
   - Added success logging with extracted text length
   - Clarified subtitle (phone is optional)

================================================================================
NEW DEPENDENCIES
================================================================================

Backend (/server/package.json):
- express: ^4.21.1
- cors: ^2.8.5
- dotenv: ^16.4.5
- pg: ^8.13.1
- multer: ^1.4.5-lts.1
- pdf-parse: ^2.2.2

Install: cd server && npm install

================================================================================
KEY FEATURES IMPLEMENTED
================================================================================

1. PDF TEXT EXTRACTION
   - Uses pdf-parse v2 API (class-based)
   - Extracts text from resume and cover letter PDFs
   - Stores in resumes.extracted_text column
   - Tested: 3,895 characters extracted successfully

2. ONE-TO-ONE EMAIL LOGIC
   - Checks if email already exists in database
   - If exists: DELETE old applicant (CASCADE removes resume)
   - Then: INSERT new application with fresh data
   - Result: Only most recent submission per email is kept

3. TRANSACTION SAFETY
   - BEGIN/COMMIT/ROLLBACK pattern
   - All operations atomic (all succeed or all fail)
   - Database never left in inconsistent state

4. FILE UPLOAD
   - Multer with memory storage (for immediate parsing)
   - 10MB limit, PDF files only
   - FormData from frontend

================================================================================
DATABASE ARCHITECTURE
================================================================================

applicants table:
  - applicant_id (PRIMARY KEY, auto-increment)
  - name (required)
  - email (required, UNIQUE) ← enforces one-to-one
  - phone (optional)
  - note (optional)
  - created_at (timestamp)

resumes table:
  - resume_id (PRIMARY KEY, auto-increment)
  - applicant_id (FOREIGN KEY → applicants ON DELETE CASCADE)
  - resume_file (filename, will be S3 URL later)
  - cover_letter_file (filename, optional)
  - extracted_text (TEXT, stores PDF content for AI search)
  - uploaded_at (timestamp)

================================================================================
TESTING STATUS
================================================================================

[PASS] Form submission with files → Server receives data
[PASS] PDF text extraction → 3,895 characters extracted
[PASS] Database insertion → Data stored correctly
[PASS] One-to-one logic → Old applicant replaced with new
[PASS] CASCADE delete → Resume auto-deleted when applicant deleted
[PASS] Transaction rollback → Errors don't corrupt database

Test Query:
  docker-compose exec db psql -U tamu -d law_portal -c \
    "SELECT applicant_id, email, created_at FROM applicants ORDER BY applicant_id;"

================================================================================
HOW TO RUN
================================================================================

1. Start Database:
   docker-compose up -d

2. Start Backend (from /server directory):
   cd server
   node src/index.js
   
   Server runs on: http://localhost:4000
   Health check: http://localhost:4000/health

3. Start Frontend (from root):
   npm run dev
   
   Frontend runs on: http://localhost:5173

================================================================================
PORTS
================================================================================

Frontend:  localhost:5173
Backend:   localhost:4000
Database:  localhost:55432 (mapped from container's 5432)

================================================================================
TODO / FUTURE ENHANCEMENTS
================================================================================

1. AWS S3 file storage (replace filenames with URLs)
2. AI-powered semantic search on extracted_text
3. Admin dashboard to view applications
4. NetID/Microsoft Entra ID authentication
5. File download endpoints

================================================================================
CRITICAL CODE SNIPPETS
================================================================================

Frontend File Upload (AdjunctApplicationPage.jsx):
  const formData = new FormData();
  formData.append('fullName', fullName);
  formData.append('email', email);
  formData.append('resume', resume);
  formData.append('coverLetter', cover);
  
  await fetch(`${API_URL}/api/applications`, {
    method: 'POST',
    body: formData
  });

Backend PDF Extraction (index.js):
  const { PDFParse } = require('pdf-parse');
  const parser = new PDFParse({ data: resumeFile.buffer });
  const resumeData = await parser.getText();
  await parser.destroy();
  const resumeText = resumeData.text || '';

Backend One-to-One Logic (index.js):
  const existingApplicant = await client.query(
    'SELECT applicant_id FROM applicants WHERE email = $1',
    [email]
  );
  
  if (existingApplicant.rows.length > 0) {
    await client.query(
      'DELETE FROM applicants WHERE applicant_id = $1',
      [existingApplicant.rows[0].applicant_id]
    );
  }

================================================================================
END OF DOCUMENT
================================================================================
